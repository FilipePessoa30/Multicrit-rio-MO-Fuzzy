{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração das planilhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo convertido: Planilhas\\AC_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\AL_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\AM_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\AP_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\BA_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\Brasil_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\CE_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\DF_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\ES_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\GO_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\MA_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\MG_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\MS_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\MT_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\PA_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\PB_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\PE_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\PI_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\PR_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\RJ_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\RN_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\RO_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\RR_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\RS_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\SC_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\SE_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\SP_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\TO_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Buscar todos os arquivos Excel (.xls) na pasta \"Planilhas\"\n",
    "file_paths = glob(os.path.join(pasta, '*.xls'))\n",
    "\n",
    "for fpath in file_paths:\n",
    "    try:\n",
    "        # Carregar o arquivo Excel\n",
    "        xls = pd.ExcelFile(fpath)\n",
    "        \n",
    "        # Verificar se existe a planilha \"Estoques_2000-2020\"\n",
    "        if \"Estoques_2000-2020\" in xls.sheet_names:\n",
    "            df_sheet = xls.parse(\"Estoques_2000-2020\")\n",
    "            \n",
    "            # Gerar nome para o CSV de saída\n",
    "            base_name = os.path.splitext(os.path.basename(fpath))[0]\n",
    "            csv_path = os.path.join(pasta, f\"{base_name}_Estoques_2000-2020.csv\")\n",
    "            \n",
    "            # Salvar a planilha em CSV\n",
    "            df_sheet.to_csv(csv_path, index=False)\n",
    "            print(f\"Arquivo convertido: {csv_path}\")\n",
    "        else:\n",
    "            print(f\"Planilha 'Estoques_2000-2020' não encontrada em {fpath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {fpath}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV salvo como estoques_fuzzy_todos_estados.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Caminho da pasta com os arquivos .xls convertidos para .csv\n",
    "pasta = \"CSV\"\n",
    "\n",
    "# Categorias relevantes para fuzzy multiobjetivo\n",
    "categorias_fuzzy = [\n",
    "    \"Área Agrícola\",\n",
    "    \"Pastagem com Manejo\",\n",
    "    \"Vegetação Florestal\",\n",
    "    \"Mosaico de Ocupações em Área Florestal\",\n",
    "    \"Mosaico de Ocupações em Área Campestre\",\n",
    "    \"Área Descoberta\",\n",
    "    \"Área Artificial\",\n",
    "    \"Área Úmida\"\n",
    "]\n",
    "\n",
    "# Lista para guardar os dados de todos os estados\n",
    "registros = []\n",
    "\n",
    "# Percorre cada arquivo na pasta\n",
    "for arquivo in os.listdir(pasta):\n",
    "    if arquivo.endswith(\".csv\"):\n",
    "        caminho_arquivo = os.path.join(pasta, arquivo)\n",
    "        estado = arquivo[:2].upper()  # extrair a sigla do estado do nome do arquivo (ex: AC, BA)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(caminho_arquivo)\n",
    "            df.rename(columns={df.columns[0]: \"Indicador\"}, inplace=True)\n",
    "\n",
    "            # Identificar linha das categorias\n",
    "            linha_categorias_index = df[df[\"Indicador\"].astype(str).str.contains(\"Estoque\", case=False, na=False)].index[0] - 1\n",
    "            categorias = df.iloc[linha_categorias_index, 1:].values\n",
    "\n",
    "            # Filtrar linhas válidas (Estoque com ano)\n",
    "            linhas_estoque = df[df[\"Indicador\"].str.contains(r\"Estoque \\(\\d{4}\\)\", na=False, regex=True)]\n",
    "\n",
    "            for _, row in linhas_estoque.iterrows():\n",
    "                ano = re.findall(r\"\\d{4}\", row[\"Indicador\"])[0]\n",
    "                valores = row[1:].values\n",
    "\n",
    "                linha_dict = {\"Estado\": estado, \"Ano\": int(ano)}\n",
    "                for cat, val in zip(categorias, valores):\n",
    "                    if isinstance(cat, str) and cat.strip() in categorias_fuzzy:\n",
    "                        linha_dict[cat.strip()] = val\n",
    "                registros.append(linha_dict)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {arquivo}: {e}\")\n",
    "\n",
    "# Criar DataFrame final\n",
    "df_final = pd.DataFrame(registros)\n",
    "\n",
    "# Ordenar colunas\n",
    "colunas_ordenadas = [\"Estado\", \"Ano\"] + [cat for cat in categorias_fuzzy if cat in df_final.columns]\n",
    "df_final = df_final[colunas_ordenadas]\n",
    "df_final = df_final.sort_values(by=[\"Estado\", \"Ano\"])\n",
    "\n",
    "# Salvar como CSV limpo e pronto para fuzzy MO\n",
    "df_final.to_csv(\"estoques_fuzzy_todos_estados.csv\", index=False)\n",
    "print(\"✅ CSV salvo como estoques_fuzzy_todos_estados.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar INPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anos disponíveis: [1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
      "✅ Arquivo gerado: inpc_alinhado_com_estoques.csv\n",
      "     Ano  INPC_Medio\n",
      "21  2000    0.430000\n",
      "31  2010    0.524167\n",
      "33  2012    0.502500\n",
      "35  2014    0.505000\n",
      "37  2016    0.533333\n",
      "39  2018    0.282500\n",
      "41  2020    0.444167\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Passo 1: Ler o arquivo manualmente\n",
    "with open(\"INPC.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    linhas = f.readlines()\n",
    "\n",
    "# Supomos que a primeira linha seja o cabeçalho separado por vírgula\n",
    "cabecalho = linhas[0].strip().split(\",\")\n",
    "dados = []\n",
    "for linha in linhas[1:]:\n",
    "    # Usar split() (que separa por espaços e tabulações)\n",
    "    partes = linha.strip().split()\n",
    "    if len(partes) >= 2:\n",
    "        dados.append(partes[:2])\n",
    "\n",
    "# Criar o DataFrame\n",
    "df = pd.DataFrame(dados, columns=cabecalho)\n",
    "\n",
    "# Passo 2: Converter a coluna \"Valor\" – trocar vírgula por ponto e converter para float\n",
    "df[\"Valor\"] = df[\"Valor\"].astype(str).str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "# Passo 3: Converter a coluna \"Data\" para datetime\n",
    "# Mapeamento dos meses de português para número\n",
    "month_map_num = {\n",
    "    'jan': '01', 'fev': '02', 'mar': '03', 'abr': '04', 'mai': '05',\n",
    "    'jun': '06', 'jul': '07', 'ago': '08', 'set': '09', 'out': '10',\n",
    "    'nov': '11', 'dez': '12'\n",
    "}\n",
    "\n",
    "def convert_date(date_str):\n",
    "    \"\"\"\n",
    "    Converte uma data no formato 'abr/79' para um datetime, assumindo o dia 01.\n",
    "    Se o ano for >= 50, assume 1900+ano; caso contrário, 2000+ano.\n",
    "    \"\"\"\n",
    "    date_str = date_str.strip()\n",
    "    partes = date_str.split(\"/\")\n",
    "    if len(partes) != 2:\n",
    "        return pd.NaT\n",
    "    mes, ano = partes[0].strip(), partes[1].strip()\n",
    "    mes_num = month_map_num.get(mes.lower())\n",
    "    if not mes_num:\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        ano_int = int(ano)\n",
    "    except:\n",
    "        return pd.NaT\n",
    "    full_year = 1900 + ano_int if ano_int >= 50 else 2000 + ano_int\n",
    "    data_formatada = f\"01/{mes_num}/{full_year}\"\n",
    "    return pd.to_datetime(data_formatada, format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "\n",
    "df[\"Data\"] = df[\"Data\"].apply(convert_date)\n",
    "\n",
    "# Remover linhas onde a conversão falhou\n",
    "df = df.dropna(subset=[\"Data\"])\n",
    "\n",
    "# Passo 4: Extrair o ano\n",
    "df[\"Ano\"] = df[\"Data\"].dt.year\n",
    "\n",
    "# Passo 5: Calcular a média do INPC por ano\n",
    "df_anual = df.groupby(\"Ano\")[\"Valor\"].mean().reset_index()\n",
    "df_anual.rename(columns={\"Valor\": \"INPC_Medio\"}, inplace=True)\n",
    "\n",
    "# Exibir os anos disponíveis para diagnóstico\n",
    "print(\"Anos disponíveis:\", df_anual[\"Ano\"].tolist())\n",
    "\n",
    "# Passo 6: Filtrar os anos que interessam (por exemplo, os anos dos estoques)\n",
    "anos_estoques = [2000, 2010, 2012, 2014, 2016, 2018, 2020]\n",
    "df_alinhado = df_anual[df_anual[\"Ano\"].isin(anos_estoques)]\n",
    "\n",
    "# Se não houver nenhum ano de interesse, salva todos os anos (para diagnóstico)\n",
    "if df_alinhado.empty:\n",
    "    print(\"Nenhum dos anos especificados foi encontrado; salvando todos os anos disponíveis.\")\n",
    "    df_alinhado = df_anual\n",
    "\n",
    "# Passo 7: Salvar o resultado em CSV\n",
    "df_alinhado.to_csv(\"inpc_alinhado_com_estoques.csv\", index=False)\n",
    "print(\"✅ Arquivo gerado: inpc_alinhado_com_estoques.csv\")\n",
    "print(df_alinhado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização e Calculo das funções Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultado do modelo fuzzy salvo em fuzzy_model_resultado.csv\n",
      "   Estado   Ano  Fuzzy_Score  Área Agrícola_mu  Pastagem com Manejo_mu  \\\n",
      "35     BR  2000     0.614753          0.666241                0.218208   \n",
      "41     BR  2020     0.613741          1.000000                0.000000   \n",
      "39     BR  2016     0.609975          0.934488                0.011766   \n",
      "40     BR  2018     0.609237          0.964993                0.006200   \n",
      "38     BR  2014     0.605333          0.906709                0.007410   \n",
      "\n",
      "    Vegetação Florestal_mu  Mosaico de Ocupações em Área Florestal_mu  \\\n",
      "35                1.000000                                   1.000000   \n",
      "41                0.920615                                   0.972096   \n",
      "39                0.925846                                   0.994539   \n",
      "40                0.923918                                   0.981723   \n",
      "38                0.931974                                   0.975747   \n",
      "\n",
      "    Mosaico de Ocupações em Área Campestre_mu  Área Descoberta_mu  \\\n",
      "35                                   0.917600        1.840491e-02   \n",
      "41                                   1.000000        1.867165e-03   \n",
      "39                                   0.998630        1.333689e-03   \n",
      "40                                   0.997650        1.110223e-16   \n",
      "38                                   0.989072        1.333689e-02   \n",
      "\n",
      "    Área Artificial_mu  Área Úmida_mu  \n",
      "35        9.756800e-02       1.000000  \n",
      "41        2.429383e-02       0.991059  \n",
      "39        1.363910e-02       0.999557  \n",
      "40        1.110223e-16       0.999410  \n",
      "38        2.180685e-02       0.996606  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Carregar a base de dados dos estoques de uso da terra\n",
    "# O arquivo deve conter as colunas \"Estado\", \"Ano\" e as variáveis dos estoques\n",
    "df = pd.read_csv(\"estoques_fuzzy_todos_estados.csv\")  # Substitua pelo nome do seu arquivo\n",
    "\n",
    "# Definir os critérios relevantes para o modelo fuzzy multiobjetivo\n",
    "criterios = [\n",
    "    \"Área Agrícola\",\n",
    "    \"Pastagem com Manejo\",\n",
    "    \"Vegetação Florestal\",\n",
    "    \"Mosaico de Ocupações em Área Florestal\",\n",
    "    \"Mosaico de Ocupações em Área Campestre\",\n",
    "    \"Área Descoberta\",\n",
    "    \"Área Artificial\",\n",
    "    \"Área Úmida\"\n",
    "]\n",
    "\n",
    "# Definir o objetivo para cada critério:\n",
    "# \"max\" indica que queremos maximizar o valor (quanto maior, melhor)\n",
    "# \"min\" indica que queremos minimizar o valor (quanto menor, melhor)\n",
    "objetivos = {\n",
    "    \"Área Agrícola\": \"max\",\n",
    "    \"Pastagem com Manejo\": \"min\",\n",
    "    \"Vegetação Florestal\": \"max\",\n",
    "    \"Mosaico de Ocupações em Área Florestal\": \"max\",\n",
    "    \"Mosaico de Ocupações em Área Campestre\": \"max\",\n",
    "    \"Área Descoberta\": \"min\",\n",
    "    \"Área Artificial\": \"min\",\n",
    "    \"Área Úmida\": \"max\"\n",
    "}\n",
    "\n",
    "# Criar uma cópia do DataFrame para aplicar a normalização sem alterar o original\n",
    "df_norm = df.copy()\n",
    "\n",
    "# Instanciar o normalizador Min-Max para ajustar os valores entre 0 e 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Aplicar a normalização para todas as colunas dos critérios\n",
    "# Isso converte os valores absolutos (em km²) para uma escala de 0 a 1\n",
    "df_norm[criterios] = scaler.fit_transform(df[criterios])\n",
    "\n",
    "# Calcular a fuzzy membership (grau de pertinência, µ) para cada critério:\n",
    "# Se o objetivo é maximizar, usamos o valor normalizado.\n",
    "# Se o objetivo é minimizar, usamos o complemento (1 - valor normalizado).\n",
    "for crit in criterios:\n",
    "    if objetivos[crit] == \"max\":\n",
    "        # Para critérios a maximizar, o valor normalizado é o grau de pertinência\n",
    "        df_norm[crit + \"_mu\"] = df_norm[crit]\n",
    "    else:\n",
    "        # Para critérios a minimizar, definimos µ como 1 - valor normalizado\n",
    "        df_norm[crit + \"_mu\"] = 1 - df_norm[crit]\n",
    "        \n",
    "# Definir a não-pertinência (ν) e hesitação (π) de forma simples:\n",
    "# Aqui, ν é o complemento de µ, e π é definido como 0 (sem incerteza adicional)\n",
    "for crit in criterios:\n",
    "    df_norm[crit + \"_nu\"] = 1 - df_norm[crit + \"_mu\"]\n",
    "    df_norm[crit + \"_pi\"] = 0  # Poderíamos ajustar se tivéssemos uma medida de incerteza\n",
    "\n",
    "# Agregar os valores fuzzy em um índice global.\n",
    "# Neste exemplo, calculamos a média simples dos graus de pertinência (µ) para todos os critérios.\n",
    "# Esse índice global serve como o \"fuzzy score\" da alternativa.\n",
    "df_norm[\"Fuzzy_Score\"] = df_norm[[crit + \"_mu\" for crit in criterios]].mean(axis=1)\n",
    "\n",
    "# Ordenar os dados de forma decrescente, de modo que as alternativas com maior fuzzy score apareçam primeiro\n",
    "df_norm = df_norm.sort_values(by=\"Fuzzy_Score\", ascending=False)\n",
    "\n",
    "# Selecionar as colunas que serão exibidas no resultado final:\n",
    "# \"Estado\", \"Ano\", o fuzzy score global e os valores µ para cada critério\n",
    "colunas_resultado = [\"Estado\", \"Ano\", \"Fuzzy_Score\"] + [crit + \"_mu\" for crit in criterios]\n",
    "resultado = df_norm[colunas_resultado]\n",
    "\n",
    "# Salvar o resultado final em um CSV para análise posterior\n",
    "resultado.to_csv(\"fuzzy_model_resultado.csv\", index=False)\n",
    "\n",
    "# Imprimir uma mensagem de confirmação e exibir as primeiras linhas do resultado\n",
    "print(\"✅ Resultado do modelo fuzzy salvo em fuzzy_model_resultado.csv\")\n",
    "print(resultado.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos perfis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultado do modelo fuzzy com 4 perfis salvo em fuzzy_model_resultado_perfis.csv\n",
      "   Estado   Ano  perfil_conservador_Fuzzy_Score  \\\n",
      "35     BR  2000                        0.781884   \n",
      "41     BR  2020                        0.772413   \n",
      "39     BR  2016                        0.772059   \n",
      "40     BR  2018                        0.771142   \n",
      "38     BR  2014                        0.767145   \n",
      "\n",
      "    perfil_produtivista_Fuzzy_Score  perfil_especulativo_Fuzzy_Score  \\\n",
      "35                         0.685876                         0.522714   \n",
      "41                         0.789685                         0.492561   \n",
      "39                         0.767578                         0.487695   \n",
      "40                         0.776887                         0.486909   \n",
      "38                         0.754522                         0.481677   \n",
      "\n",
      "    perfil_exportador_Fuzzy_Score  \n",
      "35                       0.724966  \n",
      "41                       0.842760  \n",
      "39                       0.820653  \n",
      "40                       0.830323  \n",
      "38                       0.807213  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Carregar a base dos estoques (assegure-se de que o arquivo contenha as colunas:\n",
    "# \"Estado\", \"Ano\", \"Área Agrícola\", \"Pastagem com Manejo\", \"Vegetação Florestal\",\n",
    "# \"Mosaico de Ocupações em Área Florestal\", \"Mosaico de Ocupações em Área Campestre\",\n",
    "# \"Área Descoberta\", \"Área Artificial\" e \"Área Úmida\")\n",
    "df = pd.read_csv(\"estoques_fuzzy_todos_estados.csv\")\n",
    "\n",
    "# Lista dos critérios a serem usados\n",
    "criterios = [\n",
    "    \"Área Agrícola\",\n",
    "    \"Pastagem com Manejo\",\n",
    "    \"Vegetação Florestal\",\n",
    "    \"Mosaico de Ocupações em Área Florestal\",\n",
    "    \"Mosaico de Ocupações em Área Campestre\",\n",
    "    \"Área Descoberta\",\n",
    "    \"Área Artificial\",\n",
    "    \"Área Úmida\"\n",
    "]\n",
    "\n",
    "# Definir o objetivo de cada critério:\n",
    "# \"max\" significa que quanto maior o valor, melhor (ex.: Vegetação Florestal)\n",
    "# \"min\" significa que quanto menor o valor, melhor (ex.: Pastagem com Manejo, Área Artificial)\n",
    "objetivos = {\n",
    "    \"Área Agrícola\": \"max\",\n",
    "    \"Pastagem com Manejo\": \"min\",\n",
    "    \"Vegetação Florestal\": \"max\",\n",
    "    \"Mosaico de Ocupações em Área Florestal\": \"max\",\n",
    "    \"Mosaico de Ocupações em Área Campestre\": \"max\",\n",
    "    \"Área Descoberta\": \"min\",\n",
    "    \"Área Artificial\": \"min\",\n",
    "    \"Área Úmida\": \"max\"\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# PASSO 1: Normalização\n",
    "# -----------------------------\n",
    "# Cria uma cópia dos dados para normalizar os critérios sem alterar o original\n",
    "df_norm = df.copy()\n",
    "\n",
    "# Normaliza os dados dos critérios para a escala 0 a 1 (Min-Max)\n",
    "scaler = MinMaxScaler()\n",
    "df_norm[criterios] = scaler.fit_transform(df[criterios])\n",
    "\n",
    "# -----------------------------\n",
    "# PASSO 2: Cálculo da Função Fuzzy (grau de pertinência, µ)\n",
    "# -----------------------------\n",
    "# Para cada critério, se o objetivo é \"max\", então µ = valor normalizado;\n",
    "# se \"min\", então µ = 1 - valor normalizado.\n",
    "for crit in criterios:\n",
    "    if objetivos[crit] == \"max\":\n",
    "        df_norm[crit + \"_mu\"] = df_norm[crit]\n",
    "    else:\n",
    "        df_norm[crit + \"_mu\"] = 1 - df_norm[crit]\n",
    "        \n",
    "# (Opcional) Definindo não-pertinência (ν) como complemento de µ e hesitação (π) como 0.\n",
    "for crit in criterios:\n",
    "    df_norm[crit + \"_nu\"] = 1 - df_norm[crit + \"_mu\"]\n",
    "    df_norm[crit + \"_pi\"] = 0  # Poderia ser ajustado se houvesse informação de incerteza\n",
    "\n",
    "# -----------------------------\n",
    "# PASSO 3: Definir os 4 perfis com pesos diferentes\n",
    "# -----------------------------\n",
    "# Perfil Conservador: valoriza a sustentabilidade, preservação ambiental e diversidade de uso.\n",
    "perfil_conservador = {\n",
    "    \"Área Agrícola\": 0.10,\n",
    "    \"Pastagem com Manejo\": 0.10,\n",
    "    \"Vegetação Florestal\": 0.30,\n",
    "    \"Mosaico de Ocupações em Área Florestal\": 0.15,\n",
    "    \"Mosaico de Ocupações em Área Campestre\": 0.15,\n",
    "    \"Área Descoberta\": 0.05,\n",
    "    \"Área Artificial\": 0.05,\n",
    "    \"Área Úmida\": 0.10\n",
    "}\n",
    "\n",
    "# Perfil Produtivista: prioriza a produção, principalmente a área agrícola.\n",
    "perfil_produtivista = {\n",
    "    \"Área Agrícola\": 0.40,\n",
    "    \"Pastagem com Manejo\": 0.10,\n",
    "    \"Vegetação Florestal\": 0.10,\n",
    "    \"Mosaico de Ocupações em Área Florestal\": 0.10,\n",
    "    \"Mosaico de Ocupações em Área Campestre\": 0.10,\n",
    "    \"Área Descoberta\": 0.05,\n",
    "    \"Área Artificial\": 0.05,\n",
    "    \"Área Úmida\": 0.10\n",
    "}\n",
    "\n",
    "# Perfil Especulativo: foca em identificar concentração de terra (alta pastagem e alta área artificial)\n",
    "perfil_especulativo = {\n",
    "    \"Área Agrícola\": 0.15,\n",
    "    \"Pastagem com Manejo\": 0.30,\n",
    "    \"Vegetação Florestal\": 0.10,\n",
    "    \"Mosaico de Ocupações em Área Florestal\": 0.10,\n",
    "    \"Mosaico de Ocupações em Área Campestre\": 0.10,\n",
    "    \"Área Descoberta\": 0.05,\n",
    "    \"Área Artificial\": 0.15,\n",
    "    \"Área Úmida\": 0.05\n",
    "}\n",
    "\n",
    "# Perfil Exportador: foca na produção para exportação (alta área agrícola e redução da vegetação nativa)\n",
    "perfil_exportador = {\n",
    "    \"Área Agrícola\": 0.40,\n",
    "    \"Pastagem com Manejo\": 0.05,\n",
    "    \"Vegetação Florestal\": 0.05,\n",
    "    \"Mosaico de Ocupações em Área Florestal\": 0.10,\n",
    "    \"Mosaico de Ocupações em Área Campestre\": 0.10,\n",
    "    \"Área Descoberta\": 0.05,\n",
    "    \"Área Artificial\": 0.05,\n",
    "    \"Área Úmida\": 0.20\n",
    "}\n",
    "\n",
    "# Agrupar os perfis num dicionário\n",
    "perfis = {\n",
    "    \"perfil_conservador\": perfil_conservador,\n",
    "    \"perfil_produtivista\": perfil_produtivista,\n",
    "    \"perfil_especulativo\": perfil_especulativo,\n",
    "    \"perfil_exportador\": perfil_exportador\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# PASSO 4: Cálculo do Fuzzy Score Ponderado para cada perfil\n",
    "# -----------------------------\n",
    "# Para cada perfil, o Fuzzy Score é calculado como a média ponderada dos valores de µ para cada critério.\n",
    "for perfil, pesos in perfis.items():\n",
    "    # Para cada linha, calcula a soma dos produtos (peso * µ) e divide pela soma dos pesos (que é 1, mas fazemos para manter a consistência)\n",
    "    df_norm[perfil + \"_Fuzzy_Score\"] = df_norm.apply(\n",
    "        lambda row: sum(row[crit + \"_mu\"] * pesos[crit] for crit in criterios) / sum(pesos.values()),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# -----------------------------\n",
    "# PASSO 5: Selecionar e salvar os resultados finais\n",
    "# -----------------------------\n",
    "# Seleciona as colunas \"Estado\", \"Ano\" e os fuzzy scores de cada perfil\n",
    "colunas_resultado = [\"Estado\", \"Ano\"] + [perfil + \"_Fuzzy_Score\" for perfil in perfis.keys()]\n",
    "resultado = df_norm[colunas_resultado]\n",
    "\n",
    "# Ordena o resultado, por exemplo, usando o fuzzy score do perfil conservador\n",
    "resultado = resultado.sort_values(by=\"perfil_conservador_Fuzzy_Score\", ascending=False)\n",
    "\n",
    "# Salvar o resultado final em um CSV para análise\n",
    "resultado.to_csv(\"fuzzy_model_resultado_perfis.csv\", index=False)\n",
    "print(\"✅ Resultado do modelo fuzzy com 4 perfis salvo em fuzzy_model_resultado_perfis.csv\")\n",
    "print(resultado.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking combinado - Melhor ano e fuzzy score por estado para cada perfil:\n",
      "   Estado  Ano_conservador  perfil_conservador_Fuzzy_Score  Ano_produtivista  \\\n",
      "2      AM             2010                        0.331360              2012   \n",
      "13     PA             2000                        0.286731              2000   \n",
      "12     MT             2000                        0.258977              2020   \n",
      "4      BA             2016                        0.256479              2020   \n",
      "10     MG             2020                        0.245505              2020   \n",
      "21     RR             2020                        0.228129              2020   \n",
      "17     PR             2000                        0.221211              2018   \n",
      "25     SP             2020                        0.217292              2020   \n",
      "22     RS             2016                        0.217054              2020   \n",
      "9      MA             2000                        0.216419              2020   \n",
      "16     PI             2020                        0.216102              2020   \n",
      "11     MS             2020                        0.216015              2020   \n",
      "15     PE             2018                        0.213237              2018   \n",
      "20     RO             2000                        0.212327              2000   \n",
      "5      CE             2020                        0.212197              2020   \n",
      "0      AC             2000                        0.211565              2000   \n",
      "23     SC             2000                        0.210534              2018   \n",
      "3      AP             2020                        0.209389              2020   \n",
      "14     PB             2020                        0.208516              2020   \n",
      "24     SE             2014                        0.204686              2014   \n",
      "7      ES             2020                        0.204412              2020   \n",
      "1      AL             2016                        0.204241              2016   \n",
      "19     RN             2012                        0.202539              2012   \n",
      "18     RJ             2000                        0.202373              2000   \n",
      "26     TO             2000                        0.200337              2020   \n",
      "6      DF             2020                        0.199952              2020   \n",
      "8      GO             2000                        0.198405              2020   \n",
      "\n",
      "    perfil_produtivista_Fuzzy_Score  Ano_especulativo  \\\n",
      "2                          0.259065              2000   \n",
      "13                         0.232916              2000   \n",
      "12                         0.291398              2000   \n",
      "4                          0.247311              2016   \n",
      "10                         0.250090              2020   \n",
      "21                         0.219607              2020   \n",
      "17                         0.246544              2016   \n",
      "25                         0.256485              2020   \n",
      "22                         0.253686              2018   \n",
      "9                          0.207997              2000   \n",
      "16                         0.213707              2020   \n",
      "11                         0.234393              2020   \n",
      "15                         0.209579              2014   \n",
      "20                         0.203682              2000   \n",
      "5                          0.206089              2020   \n",
      "0                          0.203783              2000   \n",
      "23                         0.209869              2000   \n",
      "3                          0.203725              2020   \n",
      "14                         0.206207              2020   \n",
      "24                         0.203606              2014   \n",
      "7                          0.203383              2020   \n",
      "1                          0.204816              2016   \n",
      "19                         0.201080              2012   \n",
      "18                         0.200510              2000   \n",
      "26                         0.204745              2000   \n",
      "6                          0.200443              2020   \n",
      "8                          0.225484              2000   \n",
      "\n",
      "    perfil_especulativo_Fuzzy_Score  Ano_exportador  \\\n",
      "2                          0.546084            2012   \n",
      "13                         0.511988            2020   \n",
      "12                         0.500007            2020   \n",
      "4                          0.521934            2020   \n",
      "10                         0.500292            2020   \n",
      "21                         0.511871            2020   \n",
      "17                         0.511599            2018   \n",
      "25                         0.494281            2020   \n",
      "22                         0.512870            2020   \n",
      "9                          0.492104            2020   \n",
      "16                         0.507494            2020   \n",
      "11                         0.479878            2020   \n",
      "15                         0.505612            2018   \n",
      "20                         0.495320            2000   \n",
      "5                          0.502258            2020   \n",
      "0                          0.502490            2000   \n",
      "23                         0.503541            2018   \n",
      "3                          0.503304            2020   \n",
      "14                         0.504473            2020   \n",
      "24                         0.502283            2014   \n",
      "7                          0.499842            2020   \n",
      "1                          0.502128            2016   \n",
      "19                         0.497201            2012   \n",
      "18                         0.493319            2000   \n",
      "26                         0.490596            2020   \n",
      "6                          0.498753            2020   \n",
      "8                          0.470343            2020   \n",
      "\n",
      "    perfil_exportador_Fuzzy_Score  \n",
      "2                        0.213900  \n",
      "13                       0.184214  \n",
      "12                       0.270782  \n",
      "4                        0.198703  \n",
      "10                       0.204502  \n",
      "21                       0.181560  \n",
      "17                       0.197080  \n",
      "25                       0.207704  \n",
      "22                       0.203497  \n",
      "9                        0.170030  \n",
      "16                       0.163156  \n",
      "11                       0.207965  \n",
      "15                       0.159715  \n",
      "20                       0.153901  \n",
      "5                        0.155866  \n",
      "0                        0.152235  \n",
      "23                       0.159658  \n",
      "3                        0.152805  \n",
      "14                       0.156198  \n",
      "24                       0.153746  \n",
      "7                        0.153766  \n",
      "1                        0.154919  \n",
      "19                       0.151148  \n",
      "18                       0.150663  \n",
      "26                       0.157068  \n",
      "6                        0.150446  \n",
      "8                        0.182003  \n",
      "✅ Ranking combinado salvo em ranking_combinado_por_perfil.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o CSV com os fuzzy scores\n",
    "df = pd.read_csv(\"fuzzy_model_resultado_perfis.csv\")\n",
    "\n",
    "# Excluir registros de \"BR\" ou \"Brasil\" para considerar somente os estados individuais\n",
    "df = df[~df[\"Estado\"].isin([\"BR\", \"Brasil\"])]\n",
    "\n",
    "# Lista dos nomes dos perfis (colunas de fuzzy score)\n",
    "profiles = [\n",
    "    \"perfil_conservador_Fuzzy_Score\", \n",
    "    \"perfil_produtivista_Fuzzy_Score\", \n",
    "    \"perfil_especulativo_Fuzzy_Score\", \n",
    "    \"perfil_exportador_Fuzzy_Score\"\n",
    "]\n",
    "\n",
    "# Dicionário para armazenar os melhores resultados por estado para cada perfil\n",
    "best_by_profile = {}\n",
    "\n",
    "# Para cada perfil, vamos agrupar por Estado e pegar a linha com o maior fuzzy score\n",
    "for profile in profiles:\n",
    "    # Para cada estado, pega o índice da linha com o máximo valor no perfil\n",
    "    # Isso retornará, para cada estado, a linha (que contém o Ano e o fuzzy score) em que o valor é máximo.\n",
    "    best = df.loc[df.groupby(\"Estado\")[profile].idxmax()].copy()\n",
    "    # Renomeia as colunas \"Ano\" e o fuzzy score para identificá-los no resultado combinado\n",
    "    best = best[[\"Estado\", \"Ano\", profile]]\n",
    "    new_year_col = \"Ano_\" + profile.split(\"_\")[1].lower()  # exemplo: \"Ano_conservador\"\n",
    "    new_score_col = profile  # mantém o nome do fuzzy score\n",
    "    best.rename(columns={\"Ano\": new_year_col, profile: new_score_col}, inplace=True)\n",
    "    \n",
    "    best_by_profile[profile] = best\n",
    "\n",
    "# Agora, vamos unir os resultados de todos os perfis usando somente \"Estado\" como chave.\n",
    "# Começamos com o DataFrame de um dos perfis e fazemos merge com os demais.\n",
    "df_combined = best_by_profile[profiles[0]]\n",
    "for profile in profiles[1:]:\n",
    "    df_combined = pd.merge(df_combined, best_by_profile[profile], on=\"Estado\", how=\"outer\")\n",
    "\n",
    "# Ordena o DataFrame combinado por um dos os fuzzy scores, se desejar (por exemplo, perfil conservador)\n",
    "df_combined.sort_values(by=\"perfil_conservador_Fuzzy_Score\", ascending=False, inplace=True)\n",
    "\n",
    "# Exibe o resultado combinado\n",
    "print(\"Ranking combinado - Melhor ano e fuzzy score por estado para cada perfil:\")\n",
    "print(df_combined)\n",
    "\n",
    "# Salva o resultado combinado em um CSV\n",
    "df_combined.to_csv(\"ranking_combinado_por_perfil.csv\", index=False)\n",
    "print(\"✅ Ranking combinado salvo em ranking_combinado_por_perfil.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
