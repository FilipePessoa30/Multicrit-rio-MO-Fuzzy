{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração das planilhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo convertido: Planilhas\\AC_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\AL_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\AM_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\AP_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\BA_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\Brasil_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\CE_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\DF_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\ES_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\GO_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\MA_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\MG_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\MS_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\MT_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\PA_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\PB_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\PE_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\PI_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\PR_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\RJ_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\RN_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\RO_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\RR_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\RS_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\SC_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\SE_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\SP_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n",
      "Arquivo convertido: Planilhas\\TO_Mudancas_Estoques_00_10_12_14_16_18_20_serie_revisada_Estoques_2000-2020.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Buscar todos os arquivos Excel (.xls) na pasta \"Planilhas\"\n",
    "file_paths = glob(os.path.join(pasta, '*.xls'))\n",
    "\n",
    "for fpath in file_paths:\n",
    "    try:\n",
    "        # Carregar o arquivo Excel\n",
    "        xls = pd.ExcelFile(fpath)\n",
    "        \n",
    "        # Verificar se existe a planilha \"Estoques_2000-2020\"\n",
    "        if \"Estoques_2000-2020\" in xls.sheet_names:\n",
    "            df_sheet = xls.parse(\"Estoques_2000-2020\")\n",
    "            \n",
    "            # Gerar nome para o CSV de saída\n",
    "            base_name = os.path.splitext(os.path.basename(fpath))[0]\n",
    "            csv_path = os.path.join(pasta, f\"{base_name}_Estoques_2000-2020.csv\")\n",
    "            \n",
    "            # Salvar a planilha em CSV\n",
    "            df_sheet.to_csv(csv_path, index=False)\n",
    "            print(f\"Arquivo convertido: {csv_path}\")\n",
    "        else:\n",
    "            print(f\"Planilha 'Estoques_2000-2020' não encontrada em {fpath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {fpath}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV salvo como estoques_fuzzy_todos_estados.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Caminho da pasta com os arquivos .xls convertidos para .csv\n",
    "pasta = \"CSV\"\n",
    "\n",
    "# Categorias relevantes para fuzzy multiobjetivo\n",
    "categorias_fuzzy = [\n",
    "    \"Área Agrícola\",\n",
    "    \"Pastagem com Manejo\",\n",
    "    \"Vegetação Florestal\",\n",
    "    \"Mosaico de Ocupações em Área Florestal\",\n",
    "    \"Mosaico de Ocupações em Área Campestre\",\n",
    "    \"Área Descoberta\",\n",
    "    \"Área Artificial\",\n",
    "    \"Área Úmida\"\n",
    "]\n",
    "\n",
    "# Lista para guardar os dados de todos os estados\n",
    "registros = []\n",
    "\n",
    "# Percorre cada arquivo na pasta\n",
    "for arquivo in os.listdir(pasta):\n",
    "    if arquivo.endswith(\".csv\"):\n",
    "        caminho_arquivo = os.path.join(pasta, arquivo)\n",
    "        estado = arquivo[:2].upper()  # extrair a sigla do estado do nome do arquivo (ex: AC, BA)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(caminho_arquivo)\n",
    "            df.rename(columns={df.columns[0]: \"Indicador\"}, inplace=True)\n",
    "\n",
    "            # Identificar linha das categorias\n",
    "            linha_categorias_index = df[df[\"Indicador\"].astype(str).str.contains(\"Estoque\", case=False, na=False)].index[0] - 1\n",
    "            categorias = df.iloc[linha_categorias_index, 1:].values\n",
    "\n",
    "            # Filtrar linhas válidas (Estoque com ano)\n",
    "            linhas_estoque = df[df[\"Indicador\"].str.contains(r\"Estoque \\(\\d{4}\\)\", na=False, regex=True)]\n",
    "\n",
    "            for _, row in linhas_estoque.iterrows():\n",
    "                ano = re.findall(r\"\\d{4}\", row[\"Indicador\"])[0]\n",
    "                valores = row[1:].values\n",
    "\n",
    "                linha_dict = {\"Estado\": estado, \"Ano\": int(ano)}\n",
    "                for cat, val in zip(categorias, valores):\n",
    "                    if isinstance(cat, str) and cat.strip() in categorias_fuzzy:\n",
    "                        linha_dict[cat.strip()] = val\n",
    "                registros.append(linha_dict)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {arquivo}: {e}\")\n",
    "\n",
    "# Criar DataFrame final\n",
    "df_final = pd.DataFrame(registros)\n",
    "\n",
    "# Ordenar colunas\n",
    "colunas_ordenadas = [\"Estado\", \"Ano\"] + [cat for cat in categorias_fuzzy if cat in df_final.columns]\n",
    "df_final = df_final[colunas_ordenadas]\n",
    "df_final = df_final.sort_values(by=[\"Estado\", \"Ano\"])\n",
    "\n",
    "# Salvar como CSV limpo e pronto para fuzzy MO\n",
    "df_final.to_csv(\"estoques_fuzzy_todos_estados.csv\", index=False)\n",
    "print(\"✅ CSV salvo como estoques_fuzzy_todos_estados.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar INPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anos disponíveis: [1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
      "✅ Arquivo gerado: inpc_alinhado_com_estoques.csv\n",
      "     Ano  INPC_Medio\n",
      "21  2000    0.430000\n",
      "31  2010    0.524167\n",
      "33  2012    0.502500\n",
      "35  2014    0.505000\n",
      "37  2016    0.533333\n",
      "39  2018    0.282500\n",
      "41  2020    0.444167\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Passo 1: Ler o arquivo manualmente\n",
    "with open(\"INPC.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    linhas = f.readlines()\n",
    "\n",
    "# Supomos que a primeira linha seja o cabeçalho separado por vírgula\n",
    "cabecalho = linhas[0].strip().split(\",\")\n",
    "dados = []\n",
    "for linha in linhas[1:]:\n",
    "    # Usar split() (que separa por espaços e tabulações)\n",
    "    partes = linha.strip().split()\n",
    "    if len(partes) >= 2:\n",
    "        dados.append(partes[:2])\n",
    "\n",
    "# Criar o DataFrame\n",
    "df = pd.DataFrame(dados, columns=cabecalho)\n",
    "\n",
    "# Passo 2: Converter a coluna \"Valor\" – trocar vírgula por ponto e converter para float\n",
    "df[\"Valor\"] = df[\"Valor\"].astype(str).str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "# Passo 3: Converter a coluna \"Data\" para datetime\n",
    "# Mapeamento dos meses de português para número\n",
    "month_map_num = {\n",
    "    'jan': '01', 'fev': '02', 'mar': '03', 'abr': '04', 'mai': '05',\n",
    "    'jun': '06', 'jul': '07', 'ago': '08', 'set': '09', 'out': '10',\n",
    "    'nov': '11', 'dez': '12'\n",
    "}\n",
    "\n",
    "def convert_date(date_str):\n",
    "    \"\"\"\n",
    "    Converte uma data no formato 'abr/79' para um datetime, assumindo o dia 01.\n",
    "    Se o ano for >= 50, assume 1900+ano; caso contrário, 2000+ano.\n",
    "    \"\"\"\n",
    "    date_str = date_str.strip()\n",
    "    partes = date_str.split(\"/\")\n",
    "    if len(partes) != 2:\n",
    "        return pd.NaT\n",
    "    mes, ano = partes[0].strip(), partes[1].strip()\n",
    "    mes_num = month_map_num.get(mes.lower())\n",
    "    if not mes_num:\n",
    "        return pd.NaT\n",
    "    try:\n",
    "        ano_int = int(ano)\n",
    "    except:\n",
    "        return pd.NaT\n",
    "    full_year = 1900 + ano_int if ano_int >= 50 else 2000 + ano_int\n",
    "    data_formatada = f\"01/{mes_num}/{full_year}\"\n",
    "    return pd.to_datetime(data_formatada, format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "\n",
    "df[\"Data\"] = df[\"Data\"].apply(convert_date)\n",
    "\n",
    "# Remover linhas onde a conversão falhou\n",
    "df = df.dropna(subset=[\"Data\"])\n",
    "\n",
    "# Passo 4: Extrair o ano\n",
    "df[\"Ano\"] = df[\"Data\"].dt.year\n",
    "\n",
    "# Passo 5: Calcular a média do INPC por ano\n",
    "df_anual = df.groupby(\"Ano\")[\"Valor\"].mean().reset_index()\n",
    "df_anual.rename(columns={\"Valor\": \"INPC_Medio\"}, inplace=True)\n",
    "\n",
    "# Exibir os anos disponíveis para diagnóstico\n",
    "print(\"Anos disponíveis:\", df_anual[\"Ano\"].tolist())\n",
    "\n",
    "# Passo 6: Filtrar os anos que interessam (por exemplo, os anos dos estoques)\n",
    "anos_estoques = [2000, 2010, 2012, 2014, 2016, 2018, 2020]\n",
    "df_alinhado = df_anual[df_anual[\"Ano\"].isin(anos_estoques)]\n",
    "\n",
    "# Se não houver nenhum ano de interesse, salva todos os anos (para diagnóstico)\n",
    "if df_alinhado.empty:\n",
    "    print(\"Nenhum dos anos especificados foi encontrado; salvando todos os anos disponíveis.\")\n",
    "    df_alinhado = df_anual\n",
    "\n",
    "# Passo 7: Salvar o resultado em CSV\n",
    "df_alinhado.to_csv(\"inpc_alinhado_com_estoques.csv\", index=False)\n",
    "print(\"✅ Arquivo gerado: inpc_alinhado_com_estoques.csv\")\n",
    "print(df_alinhado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização e Calculo das funções Fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultado do modelo fuzzy salvo em fuzzy_model_resultado.csv\n",
      "   Estado   Ano  Fuzzy_Score  Área Agrícola_mu  Pastagem com Manejo_mu  \\\n",
      "35     BR  2000     0.614753          0.666241                0.218208   \n",
      "41     BR  2020     0.613741          1.000000                0.000000   \n",
      "39     BR  2016     0.609975          0.934488                0.011766   \n",
      "40     BR  2018     0.609237          0.964993                0.006200   \n",
      "38     BR  2014     0.605333          0.906709                0.007410   \n",
      "\n",
      "    Vegetação Florestal_mu  Mosaico de Ocupações em Área Florestal_mu  \\\n",
      "35                1.000000                                   1.000000   \n",
      "41                0.920615                                   0.972096   \n",
      "39                0.925846                                   0.994539   \n",
      "40                0.923918                                   0.981723   \n",
      "38                0.931974                                   0.975747   \n",
      "\n",
      "    Mosaico de Ocupações em Área Campestre_mu  Área Descoberta_mu  \\\n",
      "35                                   0.917600        1.840491e-02   \n",
      "41                                   1.000000        1.867165e-03   \n",
      "39                                   0.998630        1.333689e-03   \n",
      "40                                   0.997650        1.110223e-16   \n",
      "38                                   0.989072        1.333689e-02   \n",
      "\n",
      "    Área Artificial_mu  Área Úmida_mu  \n",
      "35        9.756800e-02       1.000000  \n",
      "41        2.429383e-02       0.991059  \n",
      "39        1.363910e-02       0.999557  \n",
      "40        1.110223e-16       0.999410  \n",
      "38        2.180685e-02       0.996606  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Carregar a base de dados dos estoques de uso da terra\n",
    "# O arquivo deve conter as colunas \"Estado\", \"Ano\" e as variáveis dos estoques\n",
    "df = pd.read_csv(\"estoques_fuzzy_todos_estados.csv\")  # Substitua pelo nome do seu arquivo\n",
    "\n",
    "# Definir os critérios relevantes para o modelo fuzzy multiobjetivo\n",
    "criterios = [\n",
    "    \"Área Agrícola\",\n",
    "    \"Pastagem com Manejo\",\n",
    "    \"Vegetação Florestal\",\n",
    "    \"Mosaico de Ocupações em Área Florestal\",\n",
    "    \"Mosaico de Ocupações em Área Campestre\",\n",
    "    \"Área Descoberta\",\n",
    "    \"Área Artificial\",\n",
    "    \"Área Úmida\"\n",
    "]\n",
    "\n",
    "# Definir o objetivo para cada critério:\n",
    "# \"max\" indica que queremos maximizar o valor (quanto maior, melhor)\n",
    "# \"min\" indica que queremos minimizar o valor (quanto menor, melhor)\n",
    "objetivos = {\n",
    "    \"Área Agrícola\": \"max\",\n",
    "    \"Pastagem com Manejo\": \"min\",\n",
    "    \"Vegetação Florestal\": \"max\",\n",
    "    \"Mosaico de Ocupações em Área Florestal\": \"max\",\n",
    "    \"Mosaico de Ocupações em Área Campestre\": \"max\",\n",
    "    \"Área Descoberta\": \"min\",\n",
    "    \"Área Artificial\": \"min\",\n",
    "    \"Área Úmida\": \"max\"\n",
    "}\n",
    "\n",
    "# Criar uma cópia do DataFrame para aplicar a normalização sem alterar o original\n",
    "df_norm = df.copy()\n",
    "\n",
    "# Instanciar o normalizador Min-Max para ajustar os valores entre 0 e 1\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Aplicar a normalização para todas as colunas dos critérios\n",
    "# Isso converte os valores absolutos (em km²) para uma escala de 0 a 1\n",
    "df_norm[criterios] = scaler.fit_transform(df[criterios])\n",
    "\n",
    "# Calcular a fuzzy membership (grau de pertinência, µ) para cada critério:\n",
    "# Se o objetivo é maximizar, usamos o valor normalizado.\n",
    "# Se o objetivo é minimizar, usamos o complemento (1 - valor normalizado).\n",
    "for crit in criterios:\n",
    "    if objetivos[crit] == \"max\":\n",
    "        # Para critérios a maximizar, o valor normalizado é o grau de pertinência\n",
    "        df_norm[crit + \"_mu\"] = df_norm[crit]\n",
    "    else:\n",
    "        # Para critérios a minimizar, definimos µ como 1 - valor normalizado\n",
    "        df_norm[crit + \"_mu\"] = 1 - df_norm[crit]\n",
    "        \n",
    "# Definir a não-pertinência (ν) e hesitação (π) de forma simples:\n",
    "# Aqui, ν é o complemento de µ, e π é definido como 0 (sem incerteza adicional)\n",
    "for crit in criterios:\n",
    "    df_norm[crit + \"_nu\"] = 1 - df_norm[crit + \"_mu\"]\n",
    "    df_norm[crit + \"_pi\"] = 0  # Poderíamos ajustar se tivéssemos uma medida de incerteza\n",
    "\n",
    "# Agregar os valores fuzzy em um índice global.\n",
    "# Neste exemplo, calculamos a média simples dos graus de pertinência (µ) para todos os critérios.\n",
    "# Esse índice global serve como o \"fuzzy score\" da alternativa.\n",
    "df_norm[\"Fuzzy_Score\"] = df_norm[[crit + \"_mu\" for crit in criterios]].mean(axis=1)\n",
    "\n",
    "# Ordenar os dados de forma decrescente, de modo que as alternativas com maior fuzzy score apareçam primeiro\n",
    "df_norm = df_norm.sort_values(by=\"Fuzzy_Score\", ascending=False)\n",
    "\n",
    "# Selecionar as colunas que serão exibidas no resultado final:\n",
    "# \"Estado\", \"Ano\", o fuzzy score global e os valores µ para cada critério\n",
    "colunas_resultado = [\"Estado\", \"Ano\", \"Fuzzy_Score\"] + [crit + \"_mu\" for crit in criterios]\n",
    "resultado = df_norm[colunas_resultado]\n",
    "\n",
    "# Salvar o resultado final em um CSV para análise posterior\n",
    "resultado.to_csv(\"fuzzy_model_resultado.csv\", index=False)\n",
    "\n",
    "# Imprimir uma mensagem de confirmação e exibir as primeiras linhas do resultado\n",
    "print(\"✅ Resultado do modelo fuzzy salvo em fuzzy_model_resultado.csv\")\n",
    "print(resultado.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
